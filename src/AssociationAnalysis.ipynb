{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import random\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "#import jieba\n",
    "#import jieba.analyse\n",
    "#import gensim\n",
    "#from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "plt.rcParams['font.sans-serif']=['SimHei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastFM import als\n",
    "from scipy import sparse\n",
    "import apriori as ap\n",
    "import freq_patt_tree as fpt\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "fpt = imp.reload(fpt)\n",
    "ap = imp.reload(ap)\n",
    "util = imp.reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_dict = ap.load_support_dict('out_large_itemsets.csv')\n",
    "ap.compute_recom_rules(support_dict, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time diff: 13.085367918014526\n"
     ]
    }
   ],
   "source": [
    "time_s = time.time()\n",
    "large_itemsets, recomm_rules = ap.run(util.yield_actionsets_from_file('../data/uid_sid_sparse.csv'), 20, 0.8,\n",
    "                                      max_large_item_len=None, use_fp_tree=True, output_support_only=False)\n",
    "time_e = time.time()\n",
    "print('time diff:', time_e - time_s)\n",
    "ap.dump(large_itemsets, recomm_rules, to_file_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_s = time.time()\n",
    "root, header = fpt.create_tree(util.yield_actionsets_from_file('../data/uid_sid_sample.csv'), 2)\n",
    "large_itemsets = fpt.compute_large_itemsets(root, header, 2)\n",
    "time_e = time.time()\n",
    "print('time diff:', time_e - time_s)\n",
    "print(large_itemsets)\n",
    "root.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util = imp.reload(util)\n",
    "util.create_itemset_from_file('../data/sample_simple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util = imp.reload(util)\n",
    "list(util.yield_itemsets_from_file('../data/sample_simple.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util = imp.reload(util)\n",
    "util.create_itemset_from_dataframe(pd.read_csv('../data/sample_simple.csv', header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "util = imp.reload(util)\n",
    "itemvec_dict = util.create_onehot_vector(util.create_itemset_from_file('../data/sample_simple.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(itemvec_dict[\"beer\"] + itemvec_dict[\"mango\"]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uservec = create_onehot_vec(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uservec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = create_user_item_matrix(df, uservec, itemvec, mimic=\"SVD++\")\n",
    "#mat = create_user_item_matrix(df, uservec, itemvec, mimic=\"MF\")\n",
    "#mat.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mat\n",
    "y = np.ones(mat.shape[0])\n",
    "X_ = sparse.csc_matrix(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = als.FMRegression(n_iter=200, init_stdev=0.1, rank=2, l2_reg_w=0.1, l2_reg_V=0.5)\n",
    "fm.fit(X_train, y_train)\n",
    "y_pred = fm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### apriori/fpgrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_puffer = pd.read_excel('180419mark_satisfied_puffer.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = df_puffer.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfp[dfp['mark'] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_apriori_rules(df_sidlookup, fn):\n",
    "    def get_sid_info(df, sid):\n",
    "        return df.loc[sid].iloc[0]['content'] + df.loc[sid].iloc[0]['slots']\n",
    "\n",
    "    fd = open(fn, 'w')\n",
    "    for index, row in df_rule.iterrows():\n",
    "        for sid in row[1].split('|'):\n",
    "            if sid == '':\n",
    "                continue\n",
    "            fd.write(\"<<< \" + sid + \":\" + get_sid_info(df_sidlookup, sid) + '\\n')\n",
    "        for sid in row[2].split('|'):\n",
    "            if sid == '':\n",
    "                continue\n",
    "            fd.write(\">>> \" + sid + \":\" + get_sid_info(df_sidlookup, sid) + '\\n')\n",
    "        fd.write('\\n')\n",
    "    fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mark_sid_type(row):\n",
    "    botid = row['source_type']\n",
    "    sid = row['sid']\n",
    "    if botid == \"audio_music\":\n",
    "        row['sid'] = \"m\" + sid\n",
    "    elif botid == \"audio_unicast\":\n",
    "        row['sid'] = \"u\" + sid\n",
    "    elif botid == \"ai.dueros.bot.short_video\":\n",
    "        row['sid'] = \"s\" + sid\n",
    "    elif botid == \"ai.dueros.bot.video_on_demand\":\n",
    "        row['sid'] = \"v\" + sid\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df1.apply(mark_sid_type, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sidlookup = dfs[['sid', 'slots', 'content', 'nlu']].set_index('sid')\n",
    "df_sidlookup.to_excel('out_sid_lookup.xlsx')\n",
    "df_sidlookup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_sidlookup.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1['sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sid = dfs[['uid', 'sid']].groupby('uid').agg(lambda x: ','.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sid.to_csv('out_uid_sid.csv', index=False, header=None, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import time\n",
    "import util\n",
    "import freq_patt_tree as fpt\n",
    "fpt = imp.reload(fpt)\n",
    "root, header = fpt.create_tree(util.yield_actionsets_from_file('../data/uid_sid_sample.csv'), min_sup=2)\n",
    "support_dict = fpt.compute_large_itemsets(root, header, min_sup=2)\n",
    "print('len(support_dict):', len(support_dict))\n",
    "root.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = imp.reload(ap)\n",
    "time_s = time.time()\n",
    "large_itemsets, recomm_rules = ap.run(util.yield_actionsets_from_file('../data/uid_sid_sample.csv'),\n",
    "                                      2, 0.2, use_fp_tree=True, output_support_only=False)\n",
    "time_e = time.time()\n",
    "print('time diff:', time_e - time_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import apriori as ap\n",
    "import imp\n",
    "import time\n",
    "import util\n",
    "ap = imp.reload(ap)\n",
    "time_s = time.time()\n",
    "large_itemsets, recomm_rules = ap.run(util.yield_actionsets_from_file('../data/uid_sid_sample.csv'),\n",
    "                                      2, 0.2, use_fp_tree=False, output_support_only=True)\n",
    "time_e = time.time()\n",
    "print('time diff:', time_e - time_s)\n",
    "ap.dump(large_itemsets, recomm_rules, to_file_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apriori as ap\n",
    "import imp\n",
    "import time\n",
    "import util\n",
    "ap = imp.reload(ap)\n",
    "time_s = time.time()\n",
    "large_itemsets, recomm_rules = ap.run(util.yield_actionsets_from_file('../data/uid_sid_sparse.csv'),\n",
    "                                      2, 0.2, use_fp_tree=True, output_support_only=True)\n",
    "time_e = time.time()\n",
    "print('time diff:', time_e - time_s)\n",
    "ap.dump(large_itemsets, recomm_rules, to_file_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpt = imp.reload(fpt)\n",
    "root, header = fpt.create_tree(util.yield_actionsets_from_file('../data/uid_sid_dense_3.csv'), min_sup=2)\n",
    "root.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util = imp.reload(util)\n",
    "len(list(util.create_itemset_from_iterator(\n",
    "    util.yield_actionsets_from_file('../data/uid_sid_dense_3.csv'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rule = pd.read_csv('out_recomm_rules_20%.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_apriori_rules(df_sidlookup, 'out_rules_display.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVD++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemset = create_item_set_from_file('out_uid_sid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemvec = create_onehot_vec(itemset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(itemvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uservec = create_onehot_vec(df_sid.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uservec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sid.loc['3F18061186542DB1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = create_user_item_matrix_compacted_sid(df_sid, uservec, itemvec, mimic=\"SVD++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemvec['u57751445013']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mat\n",
    "y = np.ones(mat.shape[0])\n",
    "X_ = sparse.csc_matrix(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = als.FMRegression(n_iter=200, init_stdev=0.1, rank=50, l2_reg_w=0.1, l2_reg_V=0.5)\n",
    "fm.fit(X_train, y_train)\n",
    "y_pred = fm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = create_user_item_predict_mat_compacted_sid('3F180611863094C1', df_sid, uservec, itemvec, mimic=\"SVD++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval = fm.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_eval[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = 1\n",
    "fd1 = open('uid_sid_sample.csv', 'w')\n",
    "for actionset in util.yield_itemsets_from_file('../data/sample_simple.csv'):\n",
    "    fd1.write(\"user\" + str(uid) + \",\")\n",
    "    uid += 1\n",
    "    fd1.write(\"|\".join(actionset) + \"\\n\")\n",
    "    \n",
    "fd1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util = imp.reload(util)\n",
    "list(util.yield_actionsets_from_file('../data/uid_sid_sample.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
