{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import random\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "#import jieba\n",
    "#import jieba.analyse\n",
    "#import gensim\n",
    "#from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] # chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apriori as ap\n",
    "import freq_patt_tree as fpt\n",
    "from fastFM import als\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "fp = imp.reload(fp)\n",
    "ap = imp.reload(ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time diff: 0.002992868423461914\n",
      "Itemset: ('mango',) support: 2.000\n",
      "Itemset: ('chicken',) support: 2.000\n",
      "Itemset: ('chicken', 'beer') support: 2.000\n",
      "Itemset: ('apple', 'rice') support: 2.000\n",
      "Itemset: ('milk', 'rice') support: 2.000\n",
      "Itemset: ('chicken', 'rice') support: 2.000\n",
      "Itemset: ('rice', 'apple', 'beer') support: 2.000\n",
      "Itemset: ('milk', 'rice', 'beer') support: 2.000\n",
      "Itemset: ('chicken', 'rice', 'beer') support: 2.000\n",
      "Itemset: ('apple', 'beer') support: 3.000\n",
      "Itemset: ('milk', 'beer') support: 3.000\n",
      "Itemset: ('rice',) support: 4.000\n",
      "Itemset: ('milk',) support: 4.000\n",
      "Itemset: ('apple',) support: 4.000\n",
      "Itemset: ('rice', 'beer') support: 4.000\n",
      "Itemset: ('beer',) support: 6.000\n",
      "Rule: ('rice',) => ('beer',) confidence: 1.000\n",
      "Rule: ('chicken',) => ('beer',) confidence: 1.000\n",
      "Rule: ('chicken',) => ('rice',) confidence: 1.000\n",
      "Rule: ('apple', 'rice') => ('beer',) confidence: 1.000\n",
      "Rule: ('rice', 'milk') => ('beer',) confidence: 1.000\n",
      "Rule: ('chicken',) => ('rice', 'beer') confidence: 1.000\n",
      "Rule: ('chicken', 'rice') => ('beer',) confidence: 1.000\n",
      "Rule: ('chicken', 'beer') => ('rice',) confidence: 1.000\n"
     ]
    }
   ],
   "source": [
    "time_s = time.time()\n",
    "large_itemsets, recomm_rules = ap.run(ap.load_file('../data/sample_simple.csv'), 2, 0.8,\n",
    "                                      use_fp_tree=False, output_support_only=True)\n",
    "time_e = time.time()\n",
    "print('time diff:', time_e - time_s)\n",
    "ap.dump(large_itemsets, recomm_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time diff: 0.002887248992919922\n",
      "defaultdict(<class 'int'>, {frozenset({'beer'}): 6, frozenset({'rice'}): 4, frozenset({'rice', 'beer'}): 4, frozenset({'apple'}): 4, frozenset({'apple', 'beer'}): 3, frozenset({'apple', 'rice'}): 2, frozenset({'rice', 'apple', 'beer'}): 2, frozenset({'chicken'}): 2, frozenset({'chicken', 'rice'}): 2, frozenset({'chicken', 'beer'}): 2, frozenset({'chicken', 'rice', 'beer'}): 2, frozenset({'mango'}): 2, frozenset({'milk'}): 4, frozenset({'milk', 'beer'}): 3, frozenset({'milk', 'rice'}): 2, frozenset({'milk', 'rice', 'beer'}): 2})\n",
      "-ROOT:1\n",
      "--beer:6\n",
      "---rice:4\n",
      "----apple:2\n",
      "-----chicken:1\n",
      "----milk:2\n",
      "-----chicken:1\n",
      "---apple:1\n",
      "---milk:1\n",
      "--apple:1\n",
      "---mango:1\n",
      "--milk:1\n",
      "---mango:1\n"
     ]
    }
   ],
   "source": [
    "time_s = time.time()\n",
    "root, header = fpt.create_tree(fpt.load_file('../data/sample_simple.csv'), 2)\n",
    "large_itemsets = fpt.compute_large_itemsets(root, header, 2)\n",
    "time_e = time.time()\n",
    "print('time diff:', time_e - time_s)\n",
    "print(large_itemsets)\n",
    "root.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_item_set_from_file(fn):\n",
    "    itemset = set()\n",
    "    fd = open(fn, 'r')\n",
    "    for line in fd:\n",
    "        for e in line.rstrip().split(','):\n",
    "            itemset.add(e)\n",
    "    fd.close()\n",
    "    return itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_item_set(df):\n",
    "    itemset = set()\n",
    "    for index, row in df.iterrows():\n",
    "        for e in row.tolist():\n",
    "            itemset.add(e)\n",
    "    itemset.remove(np.nan)\n",
    "    return itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemset = create_item_set(df)\n",
    "itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_onehot_vec(itemset):\n",
    "    items = list(itemset)\n",
    "    itemvec = sparse.eye(len(items))\n",
    "    itemvec_dict = {}\n",
    "    for i in range(len(items)):\n",
    "        itemvec_dict[items[i]] = itemvec.getrow(i)\n",
    "    return itemvec_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itemvec = create_onehot_vec(itemset)\n",
    "itemvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(itemvec[\"beer\"] + itemvec[\"mango\"]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uservec = create_onehot_vec(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uservec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_item_matrix(df, uservec, itemvec, mimic=\"SVD++\"):\n",
    "    mat = None\n",
    "    for index, row in df.iterrows():\n",
    "        vu = uservec[index]\n",
    "        vi_sum = None\n",
    "        if mimic != \"MF\":\n",
    "            for item_name in row.tolist():\n",
    "                if item_name is np.nan:\n",
    "                    continue\n",
    "                vi = itemvec[item_name]\n",
    "                if vi_sum is None:\n",
    "                    vi_sum = vi\n",
    "                else:\n",
    "                    vi_sum += vi\n",
    "        if mimic == \"SVD++\":\n",
    "            vi_sum /= np.sqrt(np.sum(vi_sum))\n",
    "        for item_name in row.tolist():\n",
    "            if item_name is np.nan:\n",
    "                continue\n",
    "            vi = itemvec[item_name]\n",
    "            if mimic == \"SVD++\":\n",
    "                vuil = sparse.hstack((vu, vi, vi_sum))\n",
    "            elif mimic == \"MF\":\n",
    "                vuil = sparse.hstack((vu, vi))\n",
    "            if mat is None:\n",
    "                mat = vuil\n",
    "            else:\n",
    "                mat = sparse.vstack((mat, vuil))\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_item_matrix_compacted_sid(df, uservec, itemvec, mimic=\"SVD++\"):\n",
    "    mat = None\n",
    "    for index, row in df.iterrows():\n",
    "        vu = uservec[index]\n",
    "        vi_sum = None\n",
    "        if mimic != \"MF\":\n",
    "            for item_name in row['sid'].split(','):\n",
    "                if item_name is np.nan:\n",
    "                    continue\n",
    "                vi = itemvec[item_name]\n",
    "                if vi_sum is None:\n",
    "                    vi_sum = vi\n",
    "                else:\n",
    "                    vi_sum += vi\n",
    "        if mimic == \"SVD++\":\n",
    "            vi_sum /= np.sqrt(np.sum(vi_sum))\n",
    "        for item_name in row['sid'].split(','):\n",
    "            if item_name is np.nan:\n",
    "                continue\n",
    "            vi = itemvec[item_name]\n",
    "            if mimic == \"SVD++\":\n",
    "                vuil = sparse.hstack((vu, vi, vi_sum))\n",
    "            elif mimic == \"MF\":\n",
    "                vuil = sparse.hstack((vu, vi))\n",
    "            if mat is None:\n",
    "                mat = vuil\n",
    "            else:\n",
    "                mat = sparse.vstack((mat, vuil))\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_item_predict_mat_compacted_sid(uid, df_sid, uservec, itemvec, mimic=\"SVD++\"):\n",
    "    mat = None\n",
    "    vu = uservec[uid]\n",
    "    if True:\n",
    "        vi_sum = None\n",
    "        if mimic != \"MF\":\n",
    "            for item_name in df_sid.loc[uid]['sid'].split(','):\n",
    "                if item_name is np.nan:\n",
    "                    continue\n",
    "                vi = itemvec[item_name]\n",
    "                if vi_sum is None:\n",
    "                    vi_sum = vi\n",
    "                else:\n",
    "                    vi_sum += vi\n",
    "        if mimic == \"SVD++\":\n",
    "            vi_sum /= np.sqrt(np.sum(vi_sum))\n",
    "        for item_name in itemvec.keys():\n",
    "            if item_name is np.nan:\n",
    "                continue\n",
    "            vi = itemvec[item_name]\n",
    "            if mimic == \"SVD++\":\n",
    "                vuil = sparse.hstack((vu, vi, vi_sum))\n",
    "            elif mimic == \"MF\":\n",
    "                vuil = sparse.hstack((vu, vi))\n",
    "            if mat is None:\n",
    "                mat = vuil\n",
    "            else:\n",
    "                mat = sparse.vstack((mat, vuil))\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = create_user_item_matrix(df, uservec, itemvec, mimic=\"SVD++\")\n",
    "#mat = create_user_item_matrix(df, uservec, itemvec, mimic=\"MF\")\n",
    "#mat.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mat\n",
    "y = np.ones(mat.shape[0])\n",
    "X_ = sparse.csc_matrix(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = als.FMRegression(n_iter=200, init_stdev=0.1, rank=2, l2_reg_w=0.1, l2_reg_V=0.5)\n",
    "fm.fit(X_train, y_train)\n",
    "y_pred = fm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### apriori/fpgrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_puffer = pd.read_excel('180419mark_satisfied_puffer.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = df_puffer.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfp[dfp['mark'] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_apriori_rules(df_sidlookup, fn):\n",
    "    def get_sid_info(df, sid):\n",
    "        return df.loc[sid].iloc[0]['content'] + df.loc[sid].iloc[0]['slots']\n",
    "\n",
    "    fd = open(fn, 'w')\n",
    "    for index, row in df_rule.iterrows():\n",
    "        for sid in row[1].split('|'):\n",
    "            if sid == '':\n",
    "                continue\n",
    "            fd.write(\"<<< \" + sid + \":\" + get_sid_info(df_sidlookup, sid) + '\\n')\n",
    "        for sid in row[2].split('|'):\n",
    "            if sid == '':\n",
    "                continue\n",
    "            fd.write(\">>> \" + sid + \":\" + get_sid_info(df_sidlookup, sid) + '\\n')\n",
    "        fd.write('\\n')\n",
    "    fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mark_sid_type(row):\n",
    "    botid = row['source_type']\n",
    "    sid = row['sid']\n",
    "    if botid == \"audio_music\":\n",
    "        row['sid'] = \"m\" + sid\n",
    "    elif botid == \"audio_unicast\":\n",
    "        row['sid'] = \"u\" + sid\n",
    "    elif botid == \"ai.dueros.bot.short_video\":\n",
    "        row['sid'] = \"s\" + sid\n",
    "    elif botid == \"ai.dueros.bot.video_on_demand\":\n",
    "        row['sid'] = \"v\" + sid\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df1.apply(mark_sid_type, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sidlookup = dfs[['sid', 'slots', 'content', 'nlu']].set_index('sid')\n",
    "df_sidlookup.to_excel('out_sid_lookup.xlsx')\n",
    "df_sidlookup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_sidlookup.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1['sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sid = dfs[['uid', 'sid']].groupby('uid').agg(lambda x: ','.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sid.to_csv('out_uid_sid.csv', index=False, header=None, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree, header = build_fp_tree('out_uid_sid.csv', support=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree.disp(fname='out_fptree.txt', df=df_sidlookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_itemsets, recomm_rules = run_apriori('out_uid_sid.csv', 0.001, 0.2)\n",
    "apriori.printResults(large_itemsets, recomm_rules, fn_items='out_large_itemsets.csv', fn_rules='out_recomm_rules.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = imp.reload(ap)\n",
    "time_s = time.time()\n",
    "large_itemsets, recomm_rules = ap.run(ap.load_file('out_uid_sid.csv'), 0.001, 0.2, output_support_only=False)\n",
    "time_e = time.time()\n",
    "print('time diff:', time_e - time_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = imp.reload(ap)\n",
    "time_s = time.time()\n",
    "large_itemsets, recomm_rules = ap.run(ap.load_file('out_uid_sid.csv'), 0.001, 0.2, output_support_only=True)\n",
    "time_e = time.time()\n",
    "print('time diff:', time_e - time_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = imp.reload(ap)\n",
    "time_s = time.time()\n",
    "large_itemsets, recomm_rules = ap.run(ap.load_file('out_uid_sid.csv'), 0.001, 0.2, use_fp_tree=False, output_support_only=False)\n",
    "time_e = time.time()\n",
    "print('time diff:', time_e - time_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap.dump(large_itemsets, recomm_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dfs['sid'] == 'm1023606622'].head()[['resource', 'query']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rule = pd.read_csv('out_recomm_rules_20%.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_apriori_rules(df_sidlookup, 'out_rules_display.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVD++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemset = create_item_set_from_file('out_uid_sid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemvec = create_onehot_vec(itemset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(itemvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uservec = create_onehot_vec(df_sid.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uservec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sid.loc['3F18061186542DB1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = create_user_item_matrix_compacted_sid(df_sid, uservec, itemvec, mimic=\"SVD++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemvec['u57751445013']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mat\n",
    "y = np.ones(mat.shape[0])\n",
    "X_ = sparse.csc_matrix(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = als.FMRegression(n_iter=200, init_stdev=0.1, rank=50, l2_reg_w=0.1, l2_reg_V=0.5)\n",
    "fm.fit(X_train, y_train)\n",
    "y_pred = fm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = create_user_item_predict_mat_compacted_sid('3F180611863094C1', df_sid, uservec, itemvec, mimic=\"SVD++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval = fm.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_eval[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
